<html>
  <head>
    <title>saucetin_minimax_single_iterative_deepening</title>
    <script
      type="text/javascript"
      src="http://epilog.stanford.edu/javascript/epilog.js"
    ></script>
    <script
      type="text/javascript"
      src="http://gamemaster.stanford.edu/javascript/localstorage.js"
    ></script>
    <script
      type="text/javascript"
      src="http://gamemaster.stanford.edu/interpreter/general.js"
    ></script>
    <script type="text/javascript">
      //==============================================================================
      // Enhanced legal player implementation with alpha-beta pruning and iterative deepening
      //==============================================================================

      var manager = "manager";
      var player = "saucetin_minimax_single_iterative_deepening";

      var role = "robot";
      var rules = [];
      var startclock = 10;
      var playclock = 10;

      var library = [];
      var roles = [];
      var state = [];

      // State cache with depth tracking
      var stateCache = {};
      var maxDepth = 3; // Initial depth for iterative deepening

      var nodeCounter = 0;
      var nodeLimit = 1000; // for example
      var startTime = 0;
      var timeLimit = 5000; // 5 seconds


      //==============================================================================

      function ping() {
        return "ready";
      }

      function start(r, rs, sc, pc) {
        role = r;
        rules = rs.slice(1);
        startclock = numberize(sc);
        playclock = numberize(pc);
        library = definemorerules([], rules);
        roles = findroles(library);
        state = findinits(library);

        // Reset cache and adjust depth based on playclock
        stateCache = {};
        maxDepth = Math.min(5, Math.floor(playclock / 2));
        return "ready";
      }

      function play(move) {
        if (move != null) state = simulate(move, state, library);
        if (findcontrol(state, library) !== role) return false;
        return findBestMove(state);
      }

      function stop(move) {
        return false;
      }
      function abort() {
        return false;
      }

      function findBestMove(currentState) {
        const legalMoves = findlegals(currentState, library);

        startTime = Date.now();
        nodeCounter = 0;

        let bestMove = legalMoves[0]; // always have a fallback

        const isMaximizing = (findcontrol(currentState, library) === role);
        let bestScore = isMaximizing ? -Infinity : Infinity;

        for (let depth = 1; depth <= 50; depth++) { // 50 is arbitrary high, stop early if limits hit
          if (Date.now() - startTime > timeLimit || nodeCounter > nodeLimit) {
            break;
          }

          let currentBestMove = null;
          let currentBestScore = isMaximizing ? -Infinity : Infinity;

          for (const move of legalMoves) {
            const nextState = simulate(move, currentState, library);
            const nextIsMaximizing = (findcontrol(nextState, library) === role);
            const score = minimax(nextState, fixedDepth - 1, nextIsMaximizing);

            if (isMaximizing) {
              if (score > bestScore) {
                bestScore = score;
                bestMove = move;
              }
            } else {
              if (score < bestScore) {
                bestScore = score;
                bestMove = move;
              }
            }
            if (Date.now() - startTime > timeLimit || nodeCounter > nodeLimit) {
              break;
            }
          }

          if (currentBestMove !== null) {
            bestMove = currentBestMove;
          }
        }
        

        return bestMove;
      }

      function minimax(state, depth, isMaximizing) {
        nodeCounter++;

        const stateKey = JSON.stringify(state);

        // Use caching if you want (optional for bounded depth)
        if (stateCache[stateKey] && stateCache[stateKey].depth >= depth) {
          return stateCache[stateKey].score;
        }

        if (findterminalp(state, library)) {
          const score = parseInt(findreward(role, state, library), 10);
          stateCache[stateKey] = { depth, score };
          return score;
        }

        if (depth === 0) {
          const score = evaluateState(state);
          stateCache[stateKey] = { depth, score };
          return score;
        }

        const legalMoves = findlegals(state, library);

        if (isMaximizing) {
          let maxEval = -Infinity;
          for (const move of legalMoves) {
            const nextState = simulate(move, state, library);
            const nextIsMaximizing = (findcontrol(nextState, library) === role);
            const eval = minimax(nextState, depth - 1, nextIsMaximizing);
            maxEval = Math.max(maxEval, eval);
            if (Date.now() - startTime > timeLimit || nodeCounter > nodeLimit) {
              break;
            }
          }
          stateCache[stateKey] = { depth, score: maxEval };
          return maxEval;
        } else {
          let minEval = Infinity;
          for (const move of legalMoves) {
            const nextState = simulate(move, state, library);
            const nextIsMaximizing = (findcontrol(nextState, library) === role);
            const eval = minimax(nextState, depth - 1, nextIsMaximizing);
            minEval = Math.min(minEval, eval);
            if (Date.now() - startTime > timeLimit || nodeCounter > nodeLimit) {
              break;
            }
          }
          stateCache[stateKey] = { depth, score: minEval };
          return minEval;
        }
      }


      function evaluateState(state) {
        // Pick the eval method depending on our strategy

        // return pessimisticEval(state);
        return mobilityEval(state);
        // return intermediateRewardEval(state);
      }

      
      function pessimisticEval(state) {
        if (findterminalp(state, library)) {
          return findreward(role, state, library) * 100; // Big weight
        }
        return 0;
      } 

      function mobilityEval(state) {
        const legalMoves = findlegals(state, library);
        if (findcontrol(state, library) === role) {
          return legalMoves.length * 10; // More moves for us
        } else {
          return -legalMoves.length * 10; // Fewer moves for opponent
        }
      }

      function intermediateRewardEval(state) {
        return findreward(role, state, library) * 100; // Immediate reward no matter what
      }

      //==============================================================================
      // End of player code
      //==============================================================================
    </script>
  </head>

  <body bgcolor="#aabbbb" onload="doinitialize()">
    <center>
      <table width="720" cellspacing="0" cellpadding="40" bgcolor="#ffffff">
        <tr>
          <td>
            <center>
              <table width="640" cellpadding="0">
                <tr>
                  <td width="180" align="center" valign="center">
                    <img
                      width="130"
                      src="http://gamemaster.stanford.edu/images/ggp.jpg"
                    />
                  </td>
                  <td align="center">
                    <span style="font-size: 18pt">&nbsp;</span>
                    <span style="font-size: 32pt">Gamemaster</span><br />
                  </td>
                  <td
                    width="180"
                    align="center"
                    style="color: #000066; font-size: 18px"
                  >
                    <i>General<br />Game<br />Playing</i>
                  </td>
                </tr>
              </table>
            </center>

            <br />
            <table
              width="640"
              cellpadding="8"
              cellspacing="0"
              bgcolor="#f4f8f8"
              border="1"
            >
              <tr height="40">
                <td align="center">
                  <table style="color: #000066; font-size: 18px">
                    <tr>
                      <td>
                        Protocol: localstorage<br />
                        Metagamer: none<br />
                        Strategy: alpha-beta with iterative deepening<br />
                        Identifier:
                        <span id="player">saucetin_minimax_single_iterative_deepening</span>
                        <img
                          src="http://gamemaster.stanford.edu/images/pencil.gif"
                          onclick="doplayer()"
                        />
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>
            </table>
            <br />

            <center>
              <br />
              <textarea
                id="transcript"
                style="font-family: courier"
                rows="30"
                cols="80"
                readonly
              ></textarea>
            </center>
          </td>
        </tr>
      </table>
    </center>
  </body>
</html>
